{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handling imbalance data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGpAjd0bERbXGkQTkRnrmB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundarp17/sundar_info5731_fall2020/blob/master/handling_imbalance_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2MwNGjR39Ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "55790811-b165-4d81-f41c-64ee94603652"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df =pd.read_csv('/content/stage-1-4.csv')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>at 994.</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Footnote:</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>People v. Francisco S. Palacios and Valerie M....</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79-0043A and 79-0044A).</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Miller v. California, 93 S. Ct. 2607, 2616 n.</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence   Target\n",
              "0                                            at 994.  Invalid\n",
              "1                                          Footnote:  Invalid\n",
              "2  People v. Francisco S. Palacios and Valerie M....  Invalid\n",
              "3                            79-0043A and 79-0044A).  Invalid\n",
              "4      Miller v. California, 93 S. Ct. 2607, 2616 n.  Invalid"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTBWixQgInzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3a812a-cfba-4300-cea4-babfce991cd6"
      },
      "source": [
        "df['Target'].unique()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Invalid', 'Facts', 'Issue', 'Rule/Law/Holding', 'Conclusion',\n",
              "       'Analysis', 'Others', 'Rule/Law/holding'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOXWDauIuaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93132c5e-bb9a-4076-ac72-26bbe16fd32b"
      },
      "source": [
        "df['Target']=df['Target'].replace(['Rule/Law/holding'],'Rule/Law/Holding')\n",
        "df['Target'].unique()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Invalid', 'Facts', 'Issue', 'Rule/Law/Holding', 'Conclusion',\n",
              "       'Analysis', 'Others'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRIvC8Ka4-bM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "567fca34-0e62-4769-af8b-c7cf5ba0c7c7"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data = df.values\n",
        "\n",
        "\n",
        "# split into input and output elements\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# label encode the target variable\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "# summarize distribution\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%s, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class=3, n=342 (9.301%)\n",
            "Class=2, n=1829 (49.742%)\n",
            "Class=4, n=263 (7.153%)\n",
            "Class=6, n=261 (7.098%)\n",
            "Class=1, n=324 (8.812%)\n",
            "Class=0, n=525 (14.278%)\n",
            "Class=5, n=133 (3.617%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhNeYSRt6U57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d3acf2-58af-41fc-9798-d8c0e45863c8"
      },
      "source": [
        "#cleaning\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "  text=\"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "  tokens = re.split('\\W+',text)\n",
        "  text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "  return text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHRx4JCcw4Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfb874b-d5fd-4288-b43a-0ed8f3fca202"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
        "X_tfidf = tfidf_vect.fit_transform(df['Sentence'])\n",
        "print(X_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3677, 6371)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r5uHE9q4D7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "870c1646-a608-4389-e8a3-9876e95d4027"
      },
      "source": [
        "#sparse matrix\n",
        "X_tfidf_df=pd.DataFrame(X_tfidf.toarray())\n",
        "X_tfidf_df.columns=tfidf_vect.get_feature_names()\n",
        "X_tfidf_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>10000</th>\n",
              "      <th>100000</th>\n",
              "      <th>10000000</th>\n",
              "      <th>10000â</th>\n",
              "      <th>1000x22</th>\n",
              "      <th>1006</th>\n",
              "      <th>1008</th>\n",
              "      <th>1008a</th>\n",
              "      <th>100x22</th>\n",
              "      <th>102</th>\n",
              "      <th>1020</th>\n",
              "      <th>1030</th>\n",
              "      <th>1042</th>\n",
              "      <th>1044</th>\n",
              "      <th>105</th>\n",
              "      <th>10511</th>\n",
              "      <th>1056</th>\n",
              "      <th>1065</th>\n",
              "      <th>107</th>\n",
              "      <th>107c</th>\n",
              "      <th>108</th>\n",
              "      <th>1084</th>\n",
              "      <th>1097</th>\n",
              "      <th>1099</th>\n",
              "      <th>10a</th>\n",
              "      <th>10acre</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>1102</th>\n",
              "      <th>111</th>\n",
              "      <th>1116</th>\n",
              "      <th>112</th>\n",
              "      <th>1120</th>\n",
              "      <th>113</th>\n",
              "      <th>1130</th>\n",
              "      <th>...</th>\n",
              "      <th>œsuccessively</th>\n",
              "      <th>œtell</th>\n",
              "      <th>œtestâ</th>\n",
              "      <th>œthat</th>\n",
              "      <th>œthatâ</th>\n",
              "      <th>œthe</th>\n",
              "      <th>œthem</th>\n",
              "      <th>œthere</th>\n",
              "      <th>œthey</th>\n",
              "      <th>œthick</th>\n",
              "      <th>œthis</th>\n",
              "      <th>œthumbusterâ</th>\n",
              "      <th>œto</th>\n",
              "      <th>œtommy</th>\n",
              "      <th>œtoo</th>\n",
              "      <th>œtwo</th>\n",
              "      <th>œunless</th>\n",
              "      <th>œupon</th>\n",
              "      <th>œvery</th>\n",
              "      <th>œvisited</th>\n",
              "      <th>œwaived</th>\n",
              "      <th>œwalked</th>\n",
              "      <th>œwas</th>\n",
              "      <th>œwe</th>\n",
              "      <th>œweaving</th>\n",
              "      <th>œwell</th>\n",
              "      <th>œwhen</th>\n",
              "      <th>œwhere</th>\n",
              "      <th>œwhether</th>\n",
              "      <th>œwhipped</th>\n",
              "      <th>œwhisky</th>\n",
              "      <th>œwhoever</th>\n",
              "      <th>œwhy</th>\n",
              "      <th>œwilliam</th>\n",
              "      <th>œwobblyâ</th>\n",
              "      <th>œwould</th>\n",
              "      <th>œyes</th>\n",
              "      <th>œyou</th>\n",
              "      <th>œyour</th>\n",
              "      <th>œyâ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6371 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          1   10  100  1000  10000  ...  œwobblyâ  œwould  œyes  œyou  œyour  œyâ\n",
              "0  0.0  0.0  0.0  0.0   0.0    0.0  ...       0.0     0.0   0.0   0.0    0.0  0.0\n",
              "1  0.0  0.0  0.0  0.0   0.0    0.0  ...       0.0     0.0   0.0   0.0    0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0   0.0    0.0  ...       0.0     0.0   0.0   0.0    0.0  0.0\n",
              "3  0.0  0.0  0.0  0.0   0.0    0.0  ...       0.0     0.0   0.0   0.0    0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0   0.0    0.0  ...       0.0     0.0   0.0   0.0    0.0  0.0\n",
              "\n",
              "[5 rows x 6371 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFk2TIOR4iVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "fd901ad2-52be-404b-abc8-82d057800d96"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(random_state=777,k_neighbors=5)\n",
        "X, y = oversample.fit_resample(X_tfidf_df, df['Target'])\n",
        "# summarize distribution\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%s, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Class=Invalid, n=1829 (14.286%)\n",
            "Class=Facts, n=1829 (14.286%)\n",
            "Class=Issue, n=1829 (14.286%)\n",
            "Class=Rule/Law/Holding, n=1829 (14.286%)\n",
            "Class=Conclusion, n=1829 (14.286%)\n",
            "Class=Analysis, n=1829 (14.286%)\n",
            "Class=Others, n=1829 (14.286%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXmyAOX3Iiww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa0a56f-2d01-4cb5-cb66-93a0251c6c89"
      },
      "source": [
        "#using smote and stochastic gradient boosting\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "X_train, x_test, Y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
        "sgd.fit(X_train, Y_train)\n",
        "pred_sgd = sgd.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(pred_sgd,y_test))\n",
        "print(classification_report(y_test,pred_sgd))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8966414996094767\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        Analysis       0.87      0.84      0.85       560\n",
            "      Conclusion       0.88      0.95      0.91       556\n",
            "           Facts       0.95      0.66      0.77       560\n",
            "         Invalid       0.87      0.92      0.90       526\n",
            "           Issue       0.90      0.98      0.94       566\n",
            "          Others       0.90      0.99      0.94       547\n",
            "Rule/Law/Holding       0.92      0.96      0.94       526\n",
            "\n",
            "        accuracy                           0.90      3841\n",
            "       macro avg       0.90      0.90      0.89      3841\n",
            "    weighted avg       0.90      0.90      0.89      3841\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etCBHy4dMQt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "07c83d62-0892-4701-84e0-9721df6ffeaf"
      },
      "source": [
        "#using RandomOverSampler\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=777)\n",
        "X_ROS, y_ROS = ros.fit_sample(X_tfidf_df, df['Target'])\n",
        "# summarize distribution\n",
        "counter = Counter(y_ROS)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y_ROS) * 100\n",
        "\tprint('Class=%s, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Class=Invalid, n=1829 (14.286%)\n",
            "Class=Facts, n=1829 (14.286%)\n",
            "Class=Issue, n=1829 (14.286%)\n",
            "Class=Rule/Law/Holding, n=1829 (14.286%)\n",
            "Class=Conclusion, n=1829 (14.286%)\n",
            "Class=Analysis, n=1829 (14.286%)\n",
            "Class=Others, n=1829 (14.286%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RxYCEa2M4xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caef5e89-6787-4e22-846d-5e5783b8a4d9"
      },
      "source": [
        "X_train, x_test, Y_train, y_test = train_test_split(X_ROS,y_ROS,test_size=0.3,random_state=42)\n",
        "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
        "sgd.fit(X_train, Y_train)\n",
        "pred_sgd = sgd.predict(x_test)\n",
        "print('Accuracy %s' % accuracy_score(pred_sgd,y_test))\n",
        "print(classification_report(y_test,pred_sgd))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8896120801874512\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        Analysis       0.87      0.80      0.84       560\n",
            "      Conclusion       0.85      0.93      0.89       556\n",
            "           Facts       0.90      0.70      0.79       560\n",
            "         Invalid       0.91      0.90      0.90       526\n",
            "           Issue       0.91      0.95      0.93       566\n",
            "          Others       0.87      0.99      0.92       547\n",
            "Rule/Law/Holding       0.92      0.96      0.94       526\n",
            "\n",
            "        accuracy                           0.89      3841\n",
            "       macro avg       0.89      0.89      0.89      3841\n",
            "    weighted avg       0.89      0.89      0.89      3841\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmsJGoG8D-Xz"
      },
      "source": [
        "Applying Bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-4txAnRD2Rz",
        "outputId": "ffcce756-56fb-4380-f622-ec983add7789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>at 994.</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Footnote:</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>People v. Francisco S. Palacios and Valerie M....</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79-0043A and 79-0044A).</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Miller v. California, 93 S. Ct. 2607, 2616 n.</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence   Target\n",
              "0                                            at 994.  Invalid\n",
              "1                                          Footnote:  Invalid\n",
              "2  People v. Francisco S. Palacios and Valerie M....  Invalid\n",
              "3                            79-0043A and 79-0044A).  Invalid\n",
              "4      Miller v. California, 93 S. Ct. 2607, 2616 n.  Invalid"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPqpZ_KLEEOm",
        "outputId": "d6faa82c-d587-4ab6-a9ad-e0bbe214dda9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['Target'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Invalid', 'Facts', 'Issue', 'Rule/Law/Holding', 'Conclusion',\n",
              "       'Analysis', 'Others'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtMq-J8eEKlP"
      },
      "source": [
        "df.loc[df['Target']=='Invalid','Target'] = 1\n",
        "df.loc[df['Target']=='Facts','Target'] = 2\n",
        "df.loc[df['Target']=='Issue','Target'] = 3\n",
        "df.loc[df['Target']=='Rule/Law/Holding','Target'] = 4\n",
        "df.loc[df['Target']=='Conclusion','Target'] = 5\n",
        "df.loc[df['Target']=='Analysis','Target'] = 6\n",
        "df.loc[df['Target']=='Others','Target'] = 7"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh8ytK68E1Pu",
        "outputId": "2737a413-11b5-41b9-ac86-a45c13583108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['Target'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bopN4IlFFQlv"
      },
      "source": [
        "'''\n",
        "BERT expects data in a specific format and the datasets are usually structured to have the following four features:\n",
        "\n",
        "guid: A unique id that represents an observation.\n",
        "text_a: The text we need to classify into given categories\n",
        "text_b: It is used when we’re training a model to understand the relationship between sentences and it does not apply for classification problems.\n",
        "label: It consists of the labels or classes or categories that a given text belongs to.\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aetLpKGiFcFc"
      },
      "source": [
        "df['Id']=df.index+1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrURqkndFftJ",
        "outputId": "297aaa13-fd09-4866-db69-05f6566e7153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Target</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>at 994.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Footnote:</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>People v. Francisco S. Palacios and Valerie M....</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79-0043A and 79-0044A).</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Miller v. California, 93 S. Ct. 2607, 2616 n.</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence Target  Id\n",
              "0                                            at 994.      1   1\n",
              "1                                          Footnote:      1   2\n",
              "2  People v. Francisco S. Palacios and Valerie M....      1   3\n",
              "3                            79-0043A and 79-0044A).      1   4\n",
              "4      Miller v. California, 93 S. Ct. 2607, 2616 n.      1   5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2oX2KiFjHD",
        "outputId": "7d7865ce-55f0-4a56-d8bf-88cfa5b862e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df=df[['Id','Sentence','Target']]\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>at 994.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Footnote:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>People v. Francisco S. Palacios and Valerie M....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>79-0043A and 79-0044A).</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Miller v. California, 93 S. Ct. 2607, 2616 n.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                           Sentence Target\n",
              "0   1                                            at 994.      1\n",
              "1   2                                          Footnote:      1\n",
              "2   3  People v. Francisco S. Palacios and Valerie M....      1\n",
              "3   4                            79-0043A and 79-0044A).      1\n",
              "4   5      Miller v. California, 93 S. Ct. 2607, 2616 n.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ-ZkcZOFu4g",
        "outputId": "e6875946-7f52-426a-8a79-c8222c167b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=0a473611c333350ec9e768237ce66ee80b5958da30e2ed6d0962769eded66087\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Sd-V9KnGWSN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgHnGZP2G7QC",
        "outputId": "538f3b5c-e6af-4d58-dab6-53e0154f53f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version :  1.15.0\n",
            "tensorflow_hub version :  0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76MACAnYHAjl",
        "outputId": "02e19c2d-ea39-42e0-b23a-6ab097d82995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Installing BERT module\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 28.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 33.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 29.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 24.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfdq2abNuG5",
        "outputId": "f7635052-61b8-4fa5-984a-68ea8981f218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip uninstall bert-tensorflow"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling bert-tensorflow-1.0.4:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/bert/*\n",
            "    /usr/local/lib/python3.6/dist-packages/bert_tensorflow-1.0.4.dist-info/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBMYFeHvN00H",
        "outputId": "9f6012d8-965f-4e0e-ead0-99caa2a7b2df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install bert-tensorflow==1.0.1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow==1.0.1 in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGFNGrl2HLAN"
      },
      "source": [
        "#Importing BERT modules\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx9xjmF5HSC4",
        "outputId": "39180e45-82fe-4690-d192-10535ae0b9a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/GD\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /GD; to attempt to forcibly remount, call drive.mount(\"/GD\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq8EjbM6HuoT"
      },
      "source": [
        "'''\n",
        "While fine-tuning the model, we will save the training checkpoints and the model in an output directory,\n",
        "so that we can use the trained model for our predictions later.\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh3HKeESH3RT",
        "outputId": "bcc2a8ee-ca91-494c-8f27-5fa21fb5b2b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "OUTPUT_DIR = '/GD/My Drive/Colab Notebooks/BERT/bert_document_category'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: /GD/My Drive/Colab Notebooks/BERT/bert_document_category *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnp10_DwIKGa",
        "outputId": "4927115e-daa3-46e5-bf20-ad677cdba915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train, val =  train_test_split(df, test_size = 0.2, random_state = 42)\n",
        "train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2490</th>\n",
              "      <td>2491</td>\n",
              "      <td>At issue is the regulation of speech.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885</th>\n",
              "      <td>2886</td>\n",
              "      <td>No brief has been filed in appellantâ€™s behalf.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3197</th>\n",
              "      <td>3198</td>\n",
              "      <td>The doctor testified that had appellant kept h...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>2899</td>\n",
              "      <td>No reversible error may be predicated upon adm...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>1054</td>\n",
              "      <td>The evidence shows a burglary of the house in ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id                                           Sentence Target\n",
              "2490  2491              At issue is the regulation of speech.      3\n",
              "2885  2886   No brief has been filed in appellantâ€™s behalf.      2\n",
              "3197  3198  The doctor testified that had appellant kept h...      2\n",
              "2898  2899  No reversible error may be predicated upon adm...      5\n",
              "1053  1054  The evidence shows a burglary of the house in ...      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7HfPFXuIe_Y",
        "outputId": "91f86a0b-3ae1-4dc8-9f31-47679231142c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(train))\n",
        "len(val)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM4Y9-l5Inas",
        "outputId": "04ce96cd-4663-445f-d549-d0309a97902c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test= pd.read_csv(r'/content/Unlabeled_data.csv')\n",
        "test.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>Complete</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>No motion for rehearing filed.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>— Relator is under accusation of killing her h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>From an order of the District Judge of the 39t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Relator and her husband had been married for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The evidence indicates that their family relat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  Complete\n",
              "0           0                     No motion for rehearing filed.         1\n",
              "1           1  — Relator is under accusation of killing her h...         1\n",
              "2           2  From an order of the District Judge of the 39t...         1\n",
              "3           3  Relator and her husband had been married for a...         1\n",
              "4           4  The evidence indicates that their family relat...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1vLYTt0JgVs",
        "outputId": "04cb6e42-803c-48aa-a234-c49d693f8f34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test.columns"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'text', 'Complete'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrRvFu3aJaMV"
      },
      "source": [
        "del test['Complete']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSmkUmIYJmFD"
      },
      "source": [
        "del test['Unnamed: 0']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb2OfMHfJs4t",
        "outputId": "4b50a71f-0134-4726-ee37-9fd2a57bccb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No motion for rehearing filed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>— Relator is under accusation of killing her h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From an order of the District Judge of the 39t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Relator and her husband had been married for a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The evidence indicates that their family relat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0                     No motion for rehearing filed.\n",
              "1  — Relator is under accusation of killing her h...\n",
              "2  From an order of the District Judge of the 39t...\n",
              "3  Relator and her husband had been married for a...\n",
              "4  The evidence indicates that their family relat..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJgzqoaFKKuD"
      },
      "source": [
        "test=test.rename(columns={'text':'Sentence'})"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-twsj41LAOp"
      },
      "source": [
        "test['Id']=test.index+1\n",
        "test=test[['Id','Sentence']]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKm8iM6VKbvR",
        "outputId": "2a4951e9-033b-4fe4-d957-1c5e3abb3702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>No motion for rehearing filed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>— Relator is under accusation of killing her h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>From an order of the District Judge of the 39t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Relator and her husband had been married for a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>The evidence indicates that their family relat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                           Sentence\n",
              "0   1                     No motion for rehearing filed.\n",
              "1   2  — Relator is under accusation of killing her h...\n",
              "2   3  From an order of the District Judge of the 39t...\n",
              "3   4  Relator and her husband had been married for a...\n",
              "4   5  The evidence indicates that their family relat..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTlBXBcGJv1g",
        "outputId": "d4891c6b-3bb8-454f-bfec-4cd3115b1036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Validation Set Shape :\", val.shape)\n",
        "print(\"Test Set Shape :\", test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (2941, 3)\n",
            "Validation Set Shape : (736, 3)\n",
            "Test Set Shape : (537703, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHgfT1U-J8ib"
      },
      "source": [
        "GUID='Id'\n",
        "DATA_COLUMN = 'Sentence'\n",
        "LABEL_COLUMN = 'Target'\n",
        "# The list containing all the classes (train['Target'].unique())\n",
        "label_list = [1, 2, 3, 4, 5, 6, 7]\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjSJLb_HKs2w"
      },
      "source": [
        "'''\n",
        "The following code block will create objects for each of the above mentioned features \n",
        "for all the records in our dataset using the InputExample class provided in the BERT library.\n",
        "'''\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=x[GUID],\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=x[GUID], \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVYJ9B0sLjVP",
        "outputId": "d42aabf4-d753-4223-a72c-c802e5da1aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2490    <bert.run_classifier.InputExample object at 0x...\n",
              "2885    <bert.run_classifier.InputExample object at 0x...\n",
              "3197    <bert.run_classifier.InputExample object at 0x...\n",
              "2898    <bert.run_classifier.InputExample object at 0x...\n",
              "1053    <bert.run_classifier.InputExample object at 0x...\n",
              "                              ...                        \n",
              "1130    <bert.run_classifier.InputExample object at 0x...\n",
              "1294    <bert.run_classifier.InputExample object at 0x...\n",
              "860     <bert.run_classifier.InputExample object at 0x...\n",
              "3507    <bert.run_classifier.InputExample object at 0x...\n",
              "3174    <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 2941, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovfPggurLtiK",
        "outputId": "0e241ac4-7bdc-41b2-d4eb-a5e14aaa6381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row 0 - guid of training set :  2491\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  At issue is the regulation of speech.\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfSjrxGYLzzY",
        "outputId": "3a42c4a0-9105-4953-b1a8-5aa02d7b0e9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "The following code block loads the pre-trained BERT model and \n",
        "initializers a tokenizer object for tokenizing the texts.\n",
        "\n",
        "I used the pre-trained bert_uncased_L-12_H-768_A-12/1 model.\n",
        "\n",
        "We will be using the vocab.txt file in the model to map the words in the dataset to indexes. \n",
        "Also the loaded BERT model is trained on uncased/lowercase data and \n",
        "hence the data we feed to train the model should also be of lowercase.\n",
        "'''\n",
        "\n",
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJemPgWgMk8T",
        "outputId": "e573fe5f-4344-42f4-b2f1-998e79065e60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Here is what the tokenised sample of the first training set observation looks like\n",
        "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['at', 'issue', 'is', 'the', 'regulation', 'of', 'speech', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rqthoCKOwss",
        "outputId": "c8dea992-dd7b-4cfe-8100-085cc3014e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#setting sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "# Converting train and validation features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 2941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 2941\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2491\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] at issue is the regulation of speech . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] at issue is the regulation of speech . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2012 3277 2003 1996 7816 1997 4613 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2012 3277 2003 1996 7816 1997 4613 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2886\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] no brief has been filed in app ##ellant ##a ##€ ##™ ##s behalf . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] no brief has been filed in app ##ellant ##a ##€ ##™ ##s behalf . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2053 4766 2038 2042 6406 1999 10439 24178 2050 30102 30108 2015 6852 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2053 4766 2038 2042 6406 1999 10439 24178 2050 30102 30108 2015 6852 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 3198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 3198\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the doctor testified that had app ##ellant kept his appointment , then he would have had time to evaluate , examine and come forward with a conclusion as to app ##ellant ##a ##€ ##™ ##s present condition . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the doctor testified that had app ##ellant kept his appointment , then he would have had time to evaluate , examine and come forward with a conclusion as to app ##ellant ##a ##€ ##™ ##s present condition . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3460 14914 2008 2018 10439 24178 2921 2010 6098 1010 2059 2002 2052 2031 2018 2051 2000 16157 1010 11628 1998 2272 2830 2007 1037 7091 2004 2000 10439 24178 2050 30102 30108 2015 2556 4650 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3460 14914 2008 2018 10439 24178 2921 2010 6098 1010 2059 2002 2052 2031 2018 2051 2000 16157 1010 11628 1998 2272 2830 2007 1037 7091 2004 2000 10439 24178 2050 30102 30108 2015 2556 4650 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2899\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] no rev ##ers ##ible error may be pre ##dicated upon admitting proof of the 1953 conviction , as similar evidence was admitted without objection . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] no rev ##ers ##ible error may be pre ##dicated upon admitting proof of the 1953 conviction , as similar evidence was admitted without objection . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2053 7065 2545 7028 7561 2089 2022 3653 26022 2588 17927 6947 1997 1996 4052 10652 1010 2004 2714 3350 2001 4914 2302 22224 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2053 7065 2545 7028 7561 2089 2022 3653 26022 2588 17927 6947 1997 1996 4052 10652 1010 2004 2714 3350 2001 4914 2302 22224 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 5 (id = 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 5 (id = 4)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 1054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 1054\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the evidence shows a bu ##rg ##lary of the house in question by someone . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the evidence shows a bu ##rg ##lary of the house in question by someone . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3350 3065 1037 20934 10623 28221 1997 1996 2160 1999 3160 2011 2619 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3350 3065 1037 20934 10623 28221 1997 1996 2160 1999 3160 2011 2619 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 736\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2130\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] there was a bullet hole in the right front fender , blood on the left door , and a man ’ s tracks leading from the left side away from the car . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] there was a bullet hole in the right front fender , blood on the left door , and a man ’ s tracks leading from the left side away from the car . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2045 2001 1037 7960 4920 1999 1996 2157 2392 19028 1010 2668 2006 1996 2187 2341 1010 1998 1037 2158 1521 1055 3162 2877 2013 1996 2187 2217 2185 2013 1996 2482 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2045 2001 1037 7960 4920 1999 1996 2157 2392 19028 1010 2668 2006 1996 2187 2341 1010 1998 1037 2158 1521 1055 3162 2877 2013 1996 2187 2217 2185 2013 1996 2482 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 1745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 1745\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a . knowles testified that shortly after midnight app ##ellant ran a red light at an intersection where they were stopped , and almost hit the squad car ; that they overtook app ##ellant ; that he had a very sl ##ur ##red speech and was very un ##stead ##y on his feet ; his eyes were watery and blood ##shot ; there was a strong odor of alcohol on his breath and he said he had been drinking . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a . knowles testified that shortly after midnight app ##ellant ran a red light at an intersection where they were stopped , and almost hit the squad car ; that they overtook app ##ellant ; that he had a very sl ##ur ##red speech and was very un ##stead ##y on his feet ; his eyes were watery and blood ##shot ; there was a strong odor of alcohol on his breath and he said he had been drinking . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 1012 22815 14914 2008 3859 2044 7090 10439 24178 2743 1037 2417 2422 2012 2019 6840 2073 2027 2020 3030 1010 1998 2471 2718 1996 4686 2482 1025 2008 2027 28920 10439 24178 1025 2008 2002 2018 1037 2200 22889 3126 5596 4613 1998 2001 2200 4895 25647 2100 2006 2010 2519 1025 2010 2159 2020 28259 1998 2668 19040 1025 2045 2001 1037 2844 19255 1997 6544 2006 2010 3052 1998 2002 2056 2002 2018 2042 5948 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 1012 22815 14914 2008 3859 2044 7090 10439 24178 2743 1037 2417 2422 2012 2019 6840 2073 2027 2020 3030 1010 1998 2471 2718 1996 4686 2482 1025 2008 2027 28920 10439 24178 1025 2008 2002 2018 1037 2200 22889 3126 5596 4613 1998 2001 2200 4895 25647 2100 2006 2010 2519 1025 2010 2159 2020 28259 1998 2668 19040 1025 2045 2001 1037 2844 19255 1997 6544 2006 2010 3052 1998 2002 2056 2002 2018 2042 5948 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 3662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 3662\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] while use of the credit card in the transaction did constitute an extent ##ion of credit to the lew ##ter feed lots company , no credit was extended by the injured party to the app ##ellant and his companions . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] while use of the credit card in the transaction did constitute an extent ##ion of credit to the lew ##ter feed lots company , no credit was extended by the injured party to the app ##ellant and his companions . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2096 2224 1997 1996 4923 4003 1999 1996 12598 2106 12346 2019 6698 3258 1997 4923 2000 1996 24992 3334 5438 7167 2194 1010 2053 4923 2001 3668 2011 1996 5229 2283 2000 1996 10439 24178 1998 2010 11946 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2096 2224 1997 1996 4923 4003 1999 1996 12598 2106 12346 2019 6698 3258 1997 4923 2000 1996 24992 3334 5438 7167 2194 1010 2053 4923 2001 3668 2011 1996 5229 2283 2000 1996 10439 24178 1998 2010 11946 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 6 (id = 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 6 (id = 5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 2846\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it was his testimony that thereafter she did not resist but suggested that they get on the bed , and a ##€ ##œ ##see ##med to be pretty willing ##a ##€ to the intercourse . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it was his testimony that thereafter she did not resist but suggested that they get on the bed , and a ##€ ##œ ##see ##med to be pretty willing ##a ##€ to the intercourse . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 2001 2010 10896 2008 6920 2016 2106 2025 9507 2021 4081 2008 2027 2131 2006 1996 2793 1010 1998 1037 30102 29674 19763 7583 2000 2022 3492 5627 2050 30102 2000 1996 23198 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 2001 2010 10896 2008 6920 2016 2106 2025 9507 2021 4081 2008 2027 2131 2006 1996 2793 1010 1998 1037 30102 29674 19763 7583 2000 2022 3492 5627 2050 30102 2000 1996 23198 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 1692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: 1692\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] we shall discuss the question raised by brief and in argument . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] we shall discuss the question raised by brief and in argument . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2057 4618 6848 1996 3160 2992 2011 4766 1998 1999 6685 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2057 4618 6848 1996 3160 2992 2011 4766 1998 1999 6685 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 2 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n85GdDHoPN6X",
        "outputId": "673995e0-ddf2-4985-f23a-b85c4c4aef5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Example on first observation in the training set\n",
        "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence :  At issue is the regulation of speech.\n",
            "------------------------------\n",
            "Tokens :  ['at', 'issue', 'is', 'the', 'regulation', 'of', 'speech', '.']\n",
            "------------------------------\n",
            "Input IDs :  [101, 2012, 3277, 2003, 1996, 7816, 1997, 4613, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh5nMO4rPWYi"
      },
      "source": [
        "'''\n",
        "creating a multi class classifer\n",
        "'''\n",
        "\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,num_labels):\n",
        "  \n",
        "  bert_module = hub.Module(BERT_MODEL_HUB,trainable=True)\n",
        "  bert_inputs = dict(input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(inputs=bert_inputs,signature=\"tokens\",as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmQrjoYzQH1C"
      },
      "source": [
        "#A function that adapts model to work for training, evaluation, and prediction.\n",
        "\n",
        "# model_fn_builder actually creates model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEWWEOugQbos"
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 300\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVU7yGR0Qmwl",
        "outputId": "af0e0640-ec56-4493-ea08-cc9db2443897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Initializing the model and the estimator\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/BERT/bert_document_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb5010add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/BERT/bert_document_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb5010add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-Yal6M8QsL9"
      },
      "source": [
        "'''\n",
        "creating an input builder function that takes training feature set (train_features) and produces a generator.\n",
        "'''\n",
        "\n",
        "# Creating an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "# Creating an input function for validating. drop_remainder = True for using TPUs.\n",
        "val_input_fn = run_classifier.input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6rlydMXRSUs",
        "outputId": "cbacfc8c-80ba-4ed4-e713-c2a82a1bd145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Training the model\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-69085d320866>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-69085d320866>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3574, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3574, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02443\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.95053506, step = 100 (97.620 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.95053506, step = 100 (97.620 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.22625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.22625\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.402454, step = 200 (81.549 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.402454, step = 200 (81.549 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 275 into /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 275 into /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.41830975.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.41830975.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:05:20.095670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvCUW1B-SyXz",
        "outputId": "b797df4f-9103-4b95-c3ba-9c2bb5388d2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluating the model with Validation set\n",
        "estimator.evaluate(input_fn=val_input_fn, steps=None)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-12-02T21:11:19Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-12-02T21:11:19Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt-275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt-275\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-12-02-21:11:32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-12-02-21:11:32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 275: eval_accuracy = 0.6399456, false_negatives = 39.0, false_positives = 26.0, global_step = 275, loss = 1.1153458, true_negatives = 46.0, true_positives = 625.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 275: eval_accuracy = 0.6399456, false_negatives = 39.0, false_positives = 26.0, global_step = 275, loss = 1.1153458, true_negatives = 46.0, true_positives = 625.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 275: /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt-275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 275: /GD/My Drive/Colab Notebooks/BERT/bert_document_category/model.ckpt-275\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.6399456,\n",
              " 'false_negatives': 39.0,\n",
              " 'false_positives': 26.0,\n",
              " 'global_step': 275,\n",
              " 'loss': 1.1153458,\n",
              " 'true_negatives': 46.0,\n",
              " 'true_positives': 625.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}